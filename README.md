# awesome-interface-agents
List of AI tools that can interact with user interfaces

## Segmenters
* [ScreenAI](https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/)
* [Llava](https://llava-vl.github.io/)
* [SegmentEverythingEverywhereAllAtOnce](https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once)

## Web browser
These are still mostly text-based
### Open Source
* [AgentLLM](https://github.com/idosal/AgentLLM)
* [LaVague](https://github.com/lavague-ai/LaVague)

### Closed Source
* [HyperWrite AI Agent](https://www.hyperwriteai.com/personal-assistant)

## Models
* [CogAgent](https://github.com/THUDM/CogVLM/tree/main?tab=readme-ov-file#introduction-to-cogagent): CogAgent is an open-source visual language model that can identify regions of areas of UIs to interact with.
* [AIOS](https://github.com/agiresearch/AIOS): Can interact with operating system

## Complete solutions
### Open Source
* [OpenAdapt.AI](https://openadapt.ai/): AI-First Process Automation with Large ([Language (LLMs) / Action (LAMs) / Multimodal (LMMs)] / Visual Language (VLMs)) Models
* [ScreenAgent](https://github.com/niuzaisheng/ScreenAgent)
* [Mobile-Agent](https://ar5iv.labs.arxiv.org/html/2401.16158v1)
* [UI-ACT](https://github.com/TobiasNorlund/UI-Act): An AI agent for interacting with a computer using the graphical user interface

### Closed Source
* [Adept](https://adept.ai): Company looking to automate everything in software

## Papers
* [Autonomous Interactive Agents](https://web.media.mit.edu/~lieber/Lieberary/Letizia/AIA/AIA.html): MIT
* [Toolformer](https://arxiv.org/abs/2302.04761)
* [Visual Programming: Compositional visual reasoning without training](https://openaccess.thecvf.com/content/CVPR2023/papers/Gupta_Visual_Programming_Compositional_Visual_Reasoning_Without_Training_CVPR_2023_paper.pdf)
